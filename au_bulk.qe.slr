#!/bin/bash
#SBATCH -p shared
#SBATCH -A csd622
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=16
#SBATCH -t 1:30:00
#SBATCH -o au_bulk.qe.%A_%a.out
#SBATCH -J au_bulk.qe
#SBATCH --export=ALL
#SBATCH --array=4-12

#testing out how slurm job arrays work, seeing the impact on k-points
#change the numbers in line 10 to alter the k-points we consider
#alternatively pass it the desired k-points as cmd-line argument


jobname=au_bulk.qe #name of file
output_format=${jobname}.${SLURM_ARRAY_JOB_ID} #what the output folder will be named

#load modules
module purge
module load slurm cpu/0.15.4  gcc/9.2.0  openmpi/3.1.6 quantum-espresso/6.7.0-openblas
module list

#define directories
#note: need separate temp folder for each task in array because QE temp files will get overwritten if they're all in same folder
# can result in "fortran runtime errors" for accessing files if not separate folder
temp_dir=/expanse/lustre/scratch/$USER/temp_project/qe/$output_format/${SLURM_ARRAY_TASK_ID} #the slurm working dir
out_dir=results/$output_format #the output dir
#code_dir=/expanse/lustre/scratch/$USER/temp_project/code/ #where a snapshot of current code will be stored

#create directories and copy files
cd $SLURM_SUBMIT_DIR
mkdir -p $temp_dir
mkdir -p $out_dir
#mkdir -p $code_dir

cp $BASH_SOURCE $out_dir/${output_format}.slr #save snapshot of sourecode at time of job run
cp ${jobname}.in $out_dir/${output_format}.in #save snapshot of input at time of job submission
cp ${jobname}.in $temp_dir #move to temp dir so we can operate on it
cd $temp_dir


k=${SLURM_ARRAY_TASK_ID} #get value for k points from slurm array task id
k_file=${jobname}.${k}_${k}_${k} #note: k is same for kx, ky, kz, since this is bulk
in_file=${k_file}.in
out_file=${k_file}.out
sed "s/%k/${k}/g" ${jobname}.in > $in_file #replace %k in input file with actual k


# use tee instead of > so that we can get periodic updates 
srun --mpi=pmi2 -n $SLURM_NPROCS pw.x -npool 1 -input $in_file | tee $out_file
cp $out_file $SLURM_SUBMIT_DIR/$out_dir
